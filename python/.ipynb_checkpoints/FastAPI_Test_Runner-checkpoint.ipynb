{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9d61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import os\n",
    "sys.path.append(os.path.abspath(r\"C:\\Users\\Jil Henry\\Documents\\Programming\\Final Year Project\\acne_diagnosis\\python\"))\n",
    "sys.path.append(os.path.abspath(r\"C:\\Users\\Jil Henry\\Documents\\Programming\\Final Year Project\\acne_diagnosis\\python\\api\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450d9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from data_preprocessing import resize_rescale\n",
    "import constants as Constants\n",
    "import data_formatter as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b59211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size,**kwargs):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "      \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"patch_size\": self.patch_size,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0cfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim,**kwargs):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection = layers.Dense(units=self.projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=self.projection_dim\n",
    "        )\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\":self.projection_dim,\n",
    "            \"projection\": self.projection,\n",
    "            \"position_embedding\": self.position_embedding,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0b5917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Getting Dataset from Storage\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    './dataset/test/',\n",
    "    image_size = (224,224),\n",
    ")\n",
    "class_names = dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5be3719c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x227701a7848>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODEL = tf.keras.models.load_model('./saved_models/10')\n",
    "MODEL = tf.keras.models.load_model('./saved_models/12/12.h5',custom_objects={'Patches': Patches, 'PatchEncoder': PatchEncoder})\n",
    "# with open('./saved_models/12/12_json.json', 'r') as json_file:\n",
    "#     json_model = json_file.read()\n",
    "# MODEL = tf.keras.models.model_from_json(json_model, custom_objects={'Patches': Patches, 'PatchEncoder': PatchEncoder})\n",
    "# load weights into new model\n",
    "MODEL.load_weights('./saved_models/12/checkpoints/checkpoint12.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e625e3bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Array Shape: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jil Henry\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "PARENT_FILE_PATH = './dataset/test/acne/'\n",
    "\n",
    "files = os.listdir(PARENT_FILE_PATH)\n",
    "images_array = []\n",
    "for file in files:\n",
    "    pil_image = tf.keras.utils.load_img(PARENT_FILE_PATH + file)\n",
    "    image_array = tf.keras.preprocessing.image.img_to_array(pil_image)\n",
    "    images_array.append(image_array)\n",
    "# print(f\"Length of Array: {len(images_array)}\")\n",
    "imgs_np_arr = np.array(images_array)\n",
    "print(f\"Image Array Shape: {imgs_np_arr.shape}\")\n",
    "# images_batch = resize_rescale(images_array)\n",
    "# print(f\"Image Batch Shape: {images_batch.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56d2f259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Array:<class 'numpy.ndarray'>\n",
      "Image Array:<class 'numpy.ndarray'>\n",
      "Image Array:<class 'numpy.ndarray'>\n",
      "Image Array:<class 'numpy.ndarray'>\n",
      "Image Array:<class 'list'>\n",
      "IMG_NP Type: <class 'numpy.ndarray'> and IMG_NP_ARR TYPE: <class 'numpy.ndarray'>\n",
      "Image NP Shape: (4, 224, 224, 3)\n",
      "Image NP Shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "images_array = []\n",
    "for images,labels in dataset.take(1):\n",
    "    for i in range(len(images)):\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "#         img_array = tf.expand_dims(img_array,0)\n",
    "        images_array.append(img_array)\n",
    "        print(f\"Image Array:{type(img_array)}\")\n",
    "#         prediction = MODEL.predict(img_array)\n",
    "#         predictions.append(prediction[0])\n",
    "# predictions\n",
    "print(f\"Image Array:{type(images_array)}\")\n",
    "img_np = np.array(images_array)\n",
    "print(f\"IMG_NP Type: {type(img_np)} and IMG_NP_ARR TYPE: {type(imgs_np_arr)}\")\n",
    "print(f\"Image NP Shape: {img_np.shape}\")\n",
    "print(f\"Image NP Shape: {imgs_np_arr.shape}\")\n",
    "# MODEL.predict(img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dff53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = MODEL.predict(images_batch)\n",
    "num_predictions = len(predictions)\n",
    "print(f\"Predictions: {predictions.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num of Predictions: {num_predictions}\")\n",
    "if num_predictions < 1:\n",
    "    print(df.format_result(\n",
    "        status='No Prediction',\n",
    "        result_type=Constants.RESULT_TYPE_CONC))\n",
    "\n",
    "pred_classes_code = np.array([], dtype='int64')\n",
    "confidence_list_total = np.zeros_like(predictions[0])\n",
    "\n",
    "if num_predictions == 1:\n",
    "    #return{\"prediction\":str(predictions)}\n",
    "    pred_class_code, confidence_list = df.format_prediction_result(\n",
    "            predictions[0])\n",
    "    #print(np.round(confidence_list.tolist()[pred_class_code],2))\n",
    "    print( df.format_result(\n",
    "            status='OK',\n",
    "            result_type=Constants.RESULT_TYPE_CONC,\n",
    "            pred_class=Constants.CLASS_NAMES[pred_class_code],\n",
    "            confidence= np.round(confidence_list.tolist()[pred_class_code],2) * 100,\n",
    "        ))\n",
    "elif num_predictions > 1:\n",
    "    for prediction in predictions:\n",
    "        pred_class_code, confidence_list = df.format_prediction_result(\n",
    "                prediction)\n",
    "        pred_classes_code = np.append(pred_classes_code, pred_class_code)\n",
    "        confidence_list_total += confidence_list\n",
    "\n",
    "    print(f\"Confidence Total = {confidence_list_total}\")\n",
    "    # Getting Number of  Most Occurring Class\n",
    "    pred_classes_code_mode = np.bincount(pred_classes_code)\n",
    "    max_num = np.max(pred_classes_code_mode)\n",
    "    pred_classes_code_mode_num = [x for x in pred_classes_code_mode if x == max_num]\n",
    "    # Return Results\n",
    "    if len(pred_classes_code_mode_num) > 1:\n",
    "        print(confidence_list_total)\n",
    "        print( df.format_result(\n",
    "              status='Inconclusive',\n",
    "              result_type=Constants.RESULT_TYPE_INCONC\n",
    "           ))\n",
    "    else:\n",
    "        index = pred_classes_code_mode.argmax()\n",
    "        print(f\"Predicted Index: {index}\")\n",
    "        confidence = np.round(((confidence_list_total[index] / num_predictions) * 100),2)\n",
    "        pred_class = Constants.CLASS_NAMES[index]\n",
    "        print( df.format_result(\n",
    "                    status='OK',\n",
    "                    result_type=Constants.RESULT_TYPE_CONC,\n",
    "                    pred_class=pred_class,\n",
    "                    confidence=confidence\n",
    "                ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
